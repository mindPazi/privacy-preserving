\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{enumitem}

\geometry{margin=1in}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

\title{Privacy-Preserving Techniques for LLM Code Completion\\
\large Repository Structure Documentation}
\author{Project Documentation}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This document describes the initial repository structure for the Privacy-Preserving Techniques for LLM Code Completion project. The repository is organized into modular components for data loading, code obfuscation, model inference, evaluation metrics, and visualization. All modules contain class and method stubs with clearly marked placeholders for future implementation.
\end{abstract}

\tableofcontents
\newpage

\section{Project Overview}

This project investigates the privacy-utility trade-off in LLM-based code completion systems. The goal is to measure how different levels of code obfuscation affect both the privacy of the input prompts and the utility of the generated completions.

\subsection{Experimental Design}

The experiment uses 20 examples from the OpenAI HumanEval dataset and generates completions using three obfuscation levels:
\begin{itemize}
    \item \textbf{None}: Original prompts without modification
    \item \textbf{Low}: Variable renaming while preserving structure
    \item \textbf{High}: Placeholder replacement and comment stripping
\end{itemize}

\subsection{Metrics}

\begin{itemize}
    \item \textbf{Utility Score}: ROUGE-L F1 comparing completion to canonical solution
    \item \textbf{Privacy Score}: Normalized Levenshtein distance from original prompt
\end{itemize}

\section{Directory Structure}

\begin{lstlisting}[language=bash,caption={Project Directory Tree}]
privacy-preserving/
|-- main.py
|-- README.md
|-- requirements.txt
|-- docs/
|   `-- structure.tex
|-- src/
|   |-- __init__.py
|   |-- data/
|   |   |-- __init__.py
|   |   `-- loader.py
|   |-- obfuscation/
|   |   |-- __init__.py
|   |   |-- base.py
|   |   |-- low_obfuscation.py
|   |   `-- high_obfuscation.py
|   |-- models/
|   |   |-- __init__.py
|   |   `-- code_completion.py
|   |-- evaluation/
|   |   |-- __init__.py
|   |   |-- utility.py
|   |   `-- privacy.py
|   `-- visualization/
|       |-- __init__.py
|       `-- plotting.py
`-- tests/
    |-- __init__.py
    |-- test_data.py
    |-- test_obfuscation.py
    `-- test_evaluation.py
\end{lstlisting}

\section{Module Descriptions}

\subsection{Data Module (\texttt{src/data/})}

\subsubsection{loader.py}

Contains the \texttt{HumanEvalDataLoader} class responsible for loading and preprocessing examples from the OpenAI HumanEval dataset.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
\textbf{Method} & \textbf{Description} \\
\midrule
\texttt{\_\_init\_\_} & Initialize with dataset name, split, and number of examples \\
\texttt{load\_dataset} & Load dataset from HuggingFace \\
\texttt{get\_prompts} & Extract code prompts from dataset \\
\texttt{get\_canonical\_solutions} & Extract canonical solutions \\
\texttt{get\_example} & Retrieve single example by index \\
\bottomrule
\end{tabular}
\caption{HumanEvalDataLoader Methods}
\end{table}

\subsection{Obfuscation Module (\texttt{src/obfuscation/})}

\subsubsection{base.py}

Defines the abstract \texttt{BaseObfuscator} class that all obfuscation strategies must implement.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
\textbf{Method} & \textbf{Description} \\
\midrule
\texttt{obfuscate} & Apply obfuscation to code (abstract) \\
\texttt{get\_mapping} & Get original to obfuscated identifier mapping (abstract) \\
\texttt{deobfuscate} & Reverse obfuscation if possible \\
\texttt{extract\_identifiers} & Extract all identifiers from code \\
\bottomrule
\end{tabular}
\caption{BaseObfuscator Methods}
\end{table}

\subsubsection{low\_obfuscation.py}

Implements \texttt{LowObfuscator} for minimal obfuscation:
\begin{itemize}
    \item Renames local variables to generic names (var1, var2, etc.)
    \item Preserves function names and code structure
    \item Keeps comments and docstrings intact
\end{itemize}

\subsubsection{high\_obfuscation.py}

Implements \texttt{HighObfuscator} for aggressive obfuscation:
\begin{itemize}
    \item Replaces all identifiers with placeholders (PLACEHOLDER\_0, etc.)
    \item Strips all comments
    \item Removes docstrings
    \item Normalizes whitespace
\end{itemize}

\subsection{Models Module (\texttt{src/models/})}

\subsubsection{code\_completion.py}

Contains the \texttt{CodeCompletionModel} class that wraps HuggingFace code completion models.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
\textbf{Method} & \textbf{Description} \\
\midrule
\texttt{\_\_init\_\_} & Initialize with model name, device, and generation parameters \\
\texttt{load\_model} & Load model and tokenizer from HuggingFace \\
\texttt{generate\_completion} & Generate completion for single prompt \\
\texttt{generate\_completions\_batch} & Generate completions for multiple prompts \\
\texttt{set\_generation\_params} & Configure generation parameters \\
\bottomrule
\end{tabular}
\caption{CodeCompletionModel Methods}
\end{table}

\subsection{Evaluation Module (\texttt{src/evaluation/})}

\subsubsection{utility.py}

Contains the \texttt{UtilityEvaluator} class for measuring completion quality.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
\textbf{Method} & \textbf{Description} \\
\midrule
\texttt{compute\_rouge\_score} & Compute ROUGE scores (1, 2, L) \\
\texttt{compute\_rouge\_batch} & Batch ROUGE computation \\
\texttt{get\_utility\_score} & Get single utility score \\
\texttt{compute\_bleu\_score} & Compute BLEU score \\
\texttt{aggregate\_scores} & Aggregate scores with statistics \\
\bottomrule
\end{tabular}
\caption{UtilityEvaluator Methods}
\end{table}

\subsubsection{privacy.py}

Contains the \texttt{PrivacyEvaluator} class for measuring prompt privacy.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
\textbf{Method} & \textbf{Description} \\
\midrule
\texttt{compute\_levenshtein\_distance} & Compute edit distance \\
\texttt{compute\_normalized\_distance} & Compute normalized distance [0,1] \\
\texttt{get\_privacy\_score} & Get privacy score for obfuscated prompt \\
\texttt{compute\_privacy\_batch} & Batch privacy computation \\
\texttt{compute\_jaccard\_distance} & Compute Jaccard distance \\
\bottomrule
\end{tabular}
\caption{PrivacyEvaluator Methods}
\end{table}

\subsection{Visualization Module (\texttt{src/visualization/})}

\subsubsection{plotting.py}

Contains the \texttt{PrivacyUtilityPlotter} class for creating visualizations.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
\textbf{Method} & \textbf{Description} \\
\midrule
\texttt{create\_scatter\_plot} & Create privacy vs. utility scatter plot \\
\texttt{create\_grouped\_scatter\_plot} & Scatter plot with obfuscation level groups \\
\texttt{add\_trend\_line} & Add linear trend line to plot \\
\texttt{add\_pareto\_frontier} & Add Pareto frontier line \\
\texttt{save\_figure} & Save figure to file \\
\bottomrule
\end{tabular}
\caption{PrivacyUtilityPlotter Methods}
\end{table}

\section{Main Entry Point (\texttt{main.py})}

The \texttt{ExperimentRunner} class orchestrates the complete experimental pipeline:

\begin{enumerate}
    \item Load HumanEval dataset (20 examples)
    \item Apply obfuscation strategies to prompts
    \item Generate code completions (60 total: 20 per obfuscation level)
    \item Evaluate utility and privacy scores
    \item Create visualizations (scatter plot)
    \item Save results
\end{enumerate}

\section{Test Suite (\texttt{tests/})}

Unit tests are organized by module:

\begin{itemize}
    \item \texttt{test\_data.py}: Tests for HumanEvalDataLoader
    \item \texttt{test\_obfuscation.py}: Tests for LowObfuscator and HighObfuscator
    \item \texttt{test\_evaluation.py}: Tests for UtilityEvaluator and PrivacyEvaluator
\end{itemize}

\section{Implementation Placeholders}

All methods in the codebase are marked with \texttt{\# TODO: [PLACEHOLDER]} comments indicating where future implementation should be added. These placeholders include:

\begin{itemize}
    \item Brief description of required functionality
    \item Key implementation steps
    \item Expected inputs and outputs
\end{itemize}

\section{Dependencies}

The project requires the following Python packages (see \texttt{requirements.txt}):

\begin{itemize}
    \item \texttt{datasets}: HuggingFace datasets library
    \item \texttt{transformers}: HuggingFace transformers library
    \item \texttt{torch}: PyTorch for model inference
    \item \texttt{rouge-score}: ROUGE metric computation
    \item \texttt{python-Levenshtein}: Levenshtein distance computation
    \item \texttt{matplotlib}: Plotting library
    \item \texttt{numpy}: Numerical computations
\end{itemize}

\section{Future Work}

\begin{enumerate}
    \item Implement all method stubs
    \item Add integration tests
    \item Create Jupyter notebook for interactive experimentation
    \item Extend with additional obfuscation strategies
    \item Add support for multiple code completion models
\end{enumerate}

\end{document}
